{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa985f4f",
   "metadata": {},
   "source": [
    "# Notebook for predicting Pitcher WAR from features via simple linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf38a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7253446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 8968\n",
      "Years available: [2015.0, 2016.0, 2017.0, 2018.0, 2019.0, 2020.0, 2021.0, 2022.0, 2023.0, 2024.0, 2025.0]\n",
      "Players with 2025 data: 349\n",
      "Rows with WAR: 8034 / 8968 (89.6%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>#days</th>\n",
       "      <th>Lev</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>SV</th>\n",
       "      <th>...</th>\n",
       "      <th>est_slg</th>\n",
       "      <th>est_slg_minus_slg_diff</th>\n",
       "      <th>woba</th>\n",
       "      <th>est_woba</th>\n",
       "      <th>est_woba_minus_woba_diff</th>\n",
       "      <th>era</th>\n",
       "      <th>xera</th>\n",
       "      <th>era_minus_xera_diff</th>\n",
       "      <th>Season</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Aardsma</td>\n",
       "      <td>33</td>\n",
       "      <td>3752</td>\n",
       "      <td>Maj-NL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fernando Abad</td>\n",
       "      <td>29</td>\n",
       "      <td>3711</td>\n",
       "      <td>Maj-AL</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.031</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.J. Achter</td>\n",
       "      <td>26</td>\n",
       "      <td>3710</td>\n",
       "      <td>Maj-AL</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austin Adams</td>\n",
       "      <td>28</td>\n",
       "      <td>3714</td>\n",
       "      <td>Maj-AL</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nathan Adcock</td>\n",
       "      <td>27</td>\n",
       "      <td>3780</td>\n",
       "      <td>Maj-NL</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Age  #days     Lev          Tm   G  GS    W    L   SV  ...  \\\n",
       "0  David Aardsma   33   3752  Maj-NL     Atlanta  33   0  1.0  1.0  NaN  ...   \n",
       "1  Fernando Abad   29   3711  Maj-AL     Oakland  62   0  2.0  2.0  NaN  ...   \n",
       "2    A.J. Achter   26   3710  Maj-AL   Minnesota  11   0  NaN  1.0  NaN  ...   \n",
       "3   Austin Adams   28   3714  Maj-AL   Cleveland  28   0  2.0  NaN  1.0  ...   \n",
       "4  Nathan Adcock   27   3780  Maj-NL  Cincinnati  13   0  1.0  2.0  NaN  ...   \n",
       "\n",
       "   est_slg  est_slg_minus_slg_diff   woba  est_woba  est_woba_minus_woba_diff  \\\n",
       "0      NaN                     NaN    NaN       NaN                       NaN   \n",
       "1    0.425                   0.067  0.342     0.311                     0.031   \n",
       "2      NaN                     NaN    NaN       NaN                       NaN   \n",
       "3      NaN                     NaN    NaN       NaN                       NaN   \n",
       "4      NaN                     NaN    NaN       NaN                       NaN   \n",
       "\n",
       "    era  xera  era_minus_xera_diff  Season   WAR  \n",
       "0   NaN   NaN                  NaN    2015 -0.13  \n",
       "1  4.15  4.02                0.134    2015  0.18  \n",
       "2   NaN   NaN                  NaN    2015 -0.18  \n",
       "3   NaN   NaN                  NaN    2015  0.30  \n",
       "4   NaN   NaN                  NaN    2015 -0.22  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the by-year data (using retry files with fixed WAR merging)\n",
    "data_yr = pd.read_csv(\"data/Pitchers_2015-2025_byYear_retry.csv\")\n",
    "print(f\"Total rows: {len(data_yr)}\")\n",
    "print(f\"Years available: {sorted(data_yr['year'].dropna().unique())}\")\n",
    "print(f\"Players with 2025 data: {len(data_yr[data_yr['year'] == 2025]['mlbID'].unique())}\")\n",
    "print(f\"Rows with WAR: {data_yr['WAR'].notna().sum()} / {len(data_yr)} ({data_yr['WAR'].notna().sum()/len(data_yr)*100:.1f}%)\")\n",
    "data_yr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c0b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-2024 rows: 738\n",
      "2025 rows: 349\n",
      "Unique players in 2023-2024: 512\n",
      "Unique players in 2025: 349\n",
      "Players with both 2023-2024 and 2025 data: 257\n"
     ]
    }
   ],
   "source": [
    "# Separate data into 2023-2024 (features) and 2025 (target)\n",
    "data_2023_2024 = data_yr[data_yr['year'].isin([2023, 2024])].copy()\n",
    "data_2025 = data_yr[data_yr['year'] == 2025].copy()\n",
    "\n",
    "print(f\"2023-2024 rows: {len(data_2023_2024)}\")\n",
    "print(f\"2025 rows: {len(data_2025)}\")\n",
    "print(f\"Unique players in 2023-2024: {data_2023_2024['mlbID'].nunique()}\")\n",
    "print(f\"Unique players in 2025: {data_2025['mlbID'].nunique()}\")\n",
    "\n",
    "# Find players who have both 2023-2024 and 2025 data\n",
    "players_with_2025 = set(data_2025['mlbID'].unique())\n",
    "players_with_2023_2024 = set(data_2023_2024['mlbID'].unique())\n",
    "common_players = players_with_2025.intersection(players_with_2023_2024)\n",
    "print(f\"Players with both 2023-2024 and 2025 data: {len(common_players)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b15e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of potential features: 67\n",
      "Sample features: ['Age', '#days', 'G', 'GS', 'W', 'L', 'SV', 'IP', 'H', 'R']\n"
     ]
    }
   ],
   "source": [
    "# Identify feature columns (exclude identifiers, year, and target)\n",
    "exclude_cols = ['Name', 'mlbID', 'year', 'Season', 'WAR', 'Name_ev', 'Name_x', \n",
    "                'Lev', 'Tm', 'team', 'position', 'team_id']\n",
    "\n",
    "# Get numeric columns that could be features\n",
    "numeric_cols = data_2023_2024.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [col for col in numeric_cols if col not in exclude_cols and col != 'WAR']\n",
    "\n",
    "print(f\"Number of potential features: {len(feature_cols)}\")\n",
    "print(f\"Sample features: {feature_cols[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each player, average their 2023-2024 features (handling NaN appropriately)\n",
    "# We'll average numeric features, but need to be careful about which ones to average vs sum\n",
    "\n",
    "def average_features_by_player(df, player_id_col='mlbID', feature_cols=None):\n",
    "    \"\"\"\n",
    "    Average features across years for each player.\n",
    "    Handles NaN by only averaging non-NaN values.\n",
    "    \"\"\"\n",
    "    if feature_cols is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        exclude_cols = ['year', 'Season', 'WAR']\n",
    "        feature_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "    \n",
    "    # Group by player and average (NaN values are ignored in mean calculation)\n",
    "    averaged = df.groupby(player_id_col)[feature_cols].mean().reset_index()\n",
    "    \n",
    "    # Also get player name for reference\n",
    "    if 'Name' in df.columns:\n",
    "        name_map = df.groupby(player_id_col)['Name'].first().reset_index()\n",
    "        averaged = averaged.merge(name_map, on=player_id_col, how='left')\n",
    "    \n",
    "    return averaged\n",
    "\n",
    "# Average 2023-2024 features for each player (for training)\n",
    "features_avg_train = average_features_by_player(data_2023_2024, feature_cols=feature_cols)\n",
    "print(f\"Training features shape (2023-2024 averaged): {features_avg_train.shape}\")\n",
    "\n",
    "# Also average 2023-2024 features for players who have 2025 data (for prediction)\n",
    "# This will be the same as features_avg_train, but we'll use it for consistency\n",
    "features_avg = features_avg_train.copy()\n",
    "print(f\"Prediction features shape: {features_avg.shape}\")\n",
    "features_avg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42491ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data: 2023-2024 features -> 2023-2024 WAR per 162\n",
    "# For each player in 2023-2024, calculate their WAR per 162\n",
    "data_2023_2024_with_war = data_2023_2024.copy()\n",
    "data_2023_2024_with_war['WAR_per_162'] = (data_2023_2024_with_war['WAR'] / data_2023_2024_with_war['G'].replace(0, pd.NA)) * 162\n",
    "\n",
    "# Average WAR per 162 across 2023-2024 for each player (for training target)\n",
    "war_per_162_train = data_2023_2024_with_war.groupby('mlbID')['WAR_per_162'].mean().reset_index()\n",
    "war_per_162_train.columns = ['mlbID', 'WAR_per_162_train']\n",
    "\n",
    "# Merge training features with training target\n",
    "train_data = features_avg_train.merge(war_per_162_train, on='mlbID', how='inner')\n",
    "\n",
    "print(\"Training Data (2023-2024):\")\n",
    "print(f\"Shape: {train_data.shape}\")\n",
    "print(f\"Players: {len(train_data)}\")\n",
    "print(f\"\\nWAR_per_162 (2023-2024 averaged) stats:\")\n",
    "print(train_data['WAR_per_162_train'].describe())\n",
    "print(f\"\\nNaN in training target: {train_data['WAR_per_162_train'].isna().sum()}\")\n",
    "\n",
    "# Prepare test data: 2023-2024 features -> 2025 WAR per 162\n",
    "# Ensure we have all required columns from data_2025\n",
    "required_cols = ['mlbID', 'WAR', 'G', 'Name']\n",
    "# Check which columns actually exist\n",
    "available_cols = [col for col in required_cols if col in data_2025.columns]\n",
    "target_2025 = data_2025[available_cols].copy()\n",
    "\n",
    "# Calculate WAR per 162 games (handle division by zero)\n",
    "if 'G' in target_2025.columns and 'WAR' in target_2025.columns:\n",
    "    target_2025['WAR_per_162_2025'] = (target_2025['WAR'] / target_2025['G'].replace(0, pd.NA)) * 162\n",
    "else:\n",
    "    raise ValueError(\"Required columns 'G' or 'WAR' not found in data_2025\")\n",
    "\n",
    "# Merge features with 2025 target (for evaluation)\n",
    "# Don't include 'G' from target_2025 since features_avg already has 'G' (from 2023-2024)\n",
    "# We only need WAR_per_162_2025 and WAR for evaluation\n",
    "merge_cols = ['mlbID', 'WAR_per_162_2025', 'WAR']\n",
    "test_data = features_avg.merge(target_2025[merge_cols], on='mlbID', how='inner')\n",
    "\n",
    "print(\"\\nTest Data (2025):\")\n",
    "print(f\"Shape: {test_data.shape}\")\n",
    "print(f\"Players: {len(test_data)}\")\n",
    "print(f\"\\nWAR_per_162_2025 stats:\")\n",
    "print(test_data['WAR_per_162_2025'].describe())\n",
    "print(f\"\\nNaN in test target: {test_data['WAR_per_162_2025'].isna().sum()}\")\n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training features and target (2023-2024)\n",
    "train_data_clean = train_data.dropna(subset=['WAR_per_162_train']).copy()\n",
    "# Only select feature columns that actually exist in the dataframe\n",
    "available_train_features = [col for col in feature_cols if col in train_data_clean.columns]\n",
    "X_train_full = train_data_clean[available_train_features].copy()\n",
    "y_train_full = train_data_clean['WAR_per_162_train'].copy()\n",
    "\n",
    "# Prepare test features and target (2025)\n",
    "test_data_clean = test_data.dropna(subset=['WAR_per_162_2025']).copy()\n",
    "\n",
    "# Debug: Check which feature columns are missing\n",
    "missing_features = [col for col in feature_cols if col not in test_data_clean.columns]\n",
    "if missing_features:\n",
    "    print(f\"Warning: {len(missing_features)} features missing from test_data: {missing_features[:10]}\")\n",
    "\n",
    "# Only select feature columns that actually exist in the dataframe\n",
    "available_test_features = [col for col in feature_cols if col in test_data_clean.columns]\n",
    "X_test = test_data_clean[available_test_features].copy()\n",
    "y_test = test_data_clean['WAR_per_162_2025'].copy()\n",
    "\n",
    "# Ensure both have the same features (use intersection)\n",
    "common_features = list(set(available_train_features) & set(available_test_features))\n",
    "X_train_full = X_train_full[common_features].copy()\n",
    "X_test = X_test[common_features].copy()\n",
    "\n",
    "print(f\"Training set: {X_train_full.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Common features used: {len(common_features)}\")\n",
    "if len(common_features) < len(feature_cols):\n",
    "    missing = set(feature_cols) - set(common_features)\n",
    "    print(f\"Features excluded (not in both datasets): {missing}\")\n",
    "\n",
    "# Handle NaN in features - we'll use median imputation for missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fit imputer on training data\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train_full),\n",
    "    columns=X_train_full.columns,\n",
    "    index=X_train_full.index\n",
    ")\n",
    "\n",
    "# Transform test data with the same imputer\n",
    "X_test_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining NaN after imputation: {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"Test NaN after imputation: {X_test_imputed.isna().sum().sum()}\")\n",
    "\n",
    "# For consistency with variable names in later cells\n",
    "X_train = X_train_imputed\n",
    "y_train = y_train_full\n",
    "X_test = X_test_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a17929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple linear regression on 2023-2024 data\n",
    "# Model learns: 2023-2024 features -> 2023-2024 WAR per 162\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "# Training predictions (on 2023-2024 data)\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "\n",
    "# Test predictions (on 2025 data, using 2023-2024 features)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"\\nTraining (2023-2024 WAR per 162):\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE: {train_mae:.3f}\")\n",
    "print(f\"  R²: {train_r2:.3f}\")\n",
    "print(f\"\\nTest (2025 WAR per 162):\")\n",
    "print(f\"  RMSE: {test_rmse:.3f}\")\n",
    "print(f\"  MAE: {test_mae:.3f}\")\n",
    "print(f\"  R²: {test_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb735dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training set (2023-2024)\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.6)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual WAR per 162 (2023-2024)')\n",
    "axes[0].set_ylabel('Predicted WAR per 162 (2023-2024)')\n",
    "axes[0].set_title(f'Train Set: 2023-2024 (R² = {train_r2:.3f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test set (2025)\n",
    "axes[1].scatter(y_test, y_test_pred, alpha=0.6)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual WAR per 162 (2025)')\n",
    "axes[1].set_ylabel('Predicted WAR per 162 (2025)')\n",
    "axes[1].set_title(f'Test Set: 2025 (R² = {test_r2:.3f})')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': lr_model.coef_\n",
    "})\n",
    "feature_importance['abs_coefficient'] = np.abs(feature_importance['coefficient'])\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 20 Most Important Features (by absolute coefficient):\")\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for all players with 2023-2024 data (even if they don't have 2025 data)\n",
    "# Model was trained on 2023-2024, now predicting 2025 WAR per 162\n",
    "\n",
    "# Prepare all players' features (2023-2024 averaged)\n",
    "# Use the same feature columns that were used for training\n",
    "all_players_features = features_avg[common_features].copy()\n",
    "all_players_features_imputed = pd.DataFrame(\n",
    "    imputer.transform(all_players_features),\n",
    "    columns=all_players_features.columns,\n",
    "    index=all_players_features.index\n",
    ")\n",
    "\n",
    "# Make predictions (these are WAR per 162 for 2025)\n",
    "all_predictions = lr_model.predict(all_players_features_imputed)\n",
    "\n",
    "# Create results dataframe\n",
    "predictions_df = features_avg[['mlbID', 'Name']].copy()\n",
    "predictions_df['predicted_WAR_per_162_2025'] = all_predictions\n",
    "\n",
    "# Recreate target_2025 to ensure it has all needed columns (in case cell 6 wasn't run)\n",
    "target_2025_for_merge = data_2025[['mlbID', 'WAR', 'G', 'Name']].copy()\n",
    "target_2025_for_merge['WAR_per_162_2025'] = (target_2025_for_merge['WAR'] / target_2025_for_merge['G'].replace(0, pd.NA)) * 162\n",
    "\n",
    "# Merge with actual 2025 WAR per 162 if available\n",
    "# Don't include 'G' in merge since predictions_df (from features_avg) already has 'G' from 2023-2024\n",
    "# This avoids G_x/G_y column name conflict\n",
    "merge_cols = ['mlbID', 'WAR_per_162_2025', 'WAR']\n",
    "predictions_df = predictions_df.merge(\n",
    "    target_2025_for_merge[merge_cols], \n",
    "    on='mlbID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add G_2025 separately if needed (rename to avoid conflict with G from features_avg)\n",
    "if 'G' in target_2025_for_merge.columns:\n",
    "    g_2025_data = target_2025_for_merge[['mlbID', 'G']].copy()\n",
    "    g_2025_data = g_2025_data.rename(columns={'G': 'G_2025'})\n",
    "    predictions_df = predictions_df.merge(g_2025_data, on='mlbID', how='left')\n",
    "\n",
    "# Sort by predicted WAR per 162\n",
    "predictions_df = predictions_df.sort_values('predicted_WAR_per_162_2025', ascending=False)\n",
    "\n",
    "# Print results - include G from features_avg and G_2025 if available\n",
    "print_cols = ['Name', 'predicted_WAR_per_162_2025', 'WAR_per_162_2025', 'WAR']\n",
    "if 'G' in predictions_df.columns:\n",
    "    print_cols.append('G')\n",
    "if 'G_2025' in predictions_df.columns:\n",
    "    print_cols.append('G_2025')\n",
    "\n",
    "print(\"Top 20 Predicted WAR per 162 2025:\")\n",
    "print(predictions_df.head(20)[print_cols].to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal players with predictions: {len(predictions_df)}\")\n",
    "print(f\"Players with actual 2025 WAR per 162: {predictions_df['WAR_per_162_2025'].notna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions vs actual for players with 2025 data\n",
    "# This is the same as the test set evaluation, but showing individual player errors\n",
    "comparison = predictions_df[predictions_df['WAR_per_162_2025'].notna()].copy()\n",
    "comparison['error'] = comparison['predicted_WAR_per_162_2025'] - comparison['WAR_per_162_2025']\n",
    "comparison['abs_error'] = np.abs(comparison['error'])\n",
    "\n",
    "print(\"Players with largest prediction errors (2025):\")\n",
    "print(comparison.nlargest(10, 'abs_error')[['Name', 'predicted_WAR_per_162_2025', 'WAR_per_162_2025', 'error']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nMean Absolute Error (all players with 2025 data): {comparison['abs_error'].mean():.3f}\")\n",
    "print(f\"RMSE (all players with 2025 data): {np.sqrt((comparison['error']**2).mean()):.3f}\")\n",
    "print(f\"\\nNote: Model trained on 2023-2024 WAR per 162, evaluated on 2025 WAR per 162\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbab1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
